##  KullanÄ±lan Teknolojiler 

Yapay Zeka ve Veri Ä°ÅŸleme (RAG Mimarisi)
* **[LangChain](https://www.langchain.com/)**
* **[ChromaDB](https://www.trychroma.com/)** 

KullanÄ±lan Modeller
* **Embedding (GÃ¶mme) Modeli:** https://huggingface.co/Qwen/Qwen3-Embedding-0.6B 
* **BÃ¼yÃ¼k Dil Modeli (LLM):** https://huggingface.co/meta-llama/Llama-3.1-8B

KullanÄ±cÄ± ArayÃ¼zÃ¼ (Frontend)
* **[React](https://react.dev/) & [Next.js](https://nextjs.org/):** 
* **[Tailwind CSS](https://tailwindcss.com/):** 


## ROADMAP V1
1) Ä°ndeksleme (Ingestion) pipelineâ€™Ä±nÄ± netleÅŸtirme
YÃ¼klenen tÃ¼m dokÃ¼manlarÄ± temiz metne Ã§evirme, parÃ§alara bÃ¶lme (chunking), embedding, ChromaDBâ€™ye yaz.
â€¢	DOCX/PDF temizleme: baÅŸlÄ±klar kalsÄ±n, gereksiz boÅŸluk/tekrarlar gitsin.
â€¢	Tablo dokÃ¼manlar: tabloyu â€œsatÄ±r bazlÄ± metinâ€e dÃ¶nÃ¼ÅŸtÃ¼r (tarihâ€“iÅŸlem eÅŸleÅŸmesi bozulmasÄ±n)
iye_surec_takvimi_2025-2026_Guz
â€¢	Chunk boyutu: 300â€“600 token aralÄ±ÄŸÄ± iyi olabilir.
â€¢	Overlap: 50â€“100 token (maddeler bÃ¶lÃ¼nmesin diye).
Kritik: â€œClassroom duyurularÄ±â€ gibi uzun bloklarÄ± konu konu ayÄ±r; tek parÃ§a olarak embed etme.
2) Metadata stratejisi kurma
Chromaâ€™ya her chunk iÃ§in ÅŸu metadataâ€™larÄ± yaz:
â€¢	source_type: yonerge / ek_form / sss / duyuru / takvim / akÄ±ÅŸ
â€¢	doc_name: dosya adÄ±
â€¢	section: baÅŸlÄ±k (varsa)
â€¢	date veya term: (takvim/duyuru gibi)
â€¢	audience: Ã¶ÄŸrenci / danÄ±ÅŸman / firma (bazen gÃ¼zel filtre olur)
Bu sayede query geldiÄŸinde:
â€¢	â€œson tarihâ€ sorularÄ±nda source_type=takvim Ã¶ncelikli aranÄ±r,
â€¢	â€œEK-7 nasÄ±l doldurulur?â€ sorusunda source_type=ek_form + yonerge Ã¶ne alÄ±nÄ±r.
3) Intent detection + routerâ€™Ä± yaz
Ã–nerilen intentâ€™ler (Ã¶rnek):
1.	selamlama
2.	sss_kisa (FAQ / kÄ±sa net cevaplar)
3.	takvim_tarih (son tarih, hangi gÃ¼n, ne zaman)
4.	belge_form (EK-1, EK-7 nasÄ±l doldurulur vs.)
5.	prosedur (baÅŸvuru sÃ¼reci, protokol vs.)
6.	teknik_destek (yÃ¼kleyemiyorum, site aÃ§Ä±lmÄ±yor)
7.	out_of_scope (dokÃ¼manda yok / alakasÄ±z)
Router kararÄ±:
â€¢	selamlama/teknik_destek:  kural tabanlÄ±
â€¢	sss_kisa: Ã¶nce JSON/FAQ matcher, bulamazsa RAG
â€¢	takvim_tarih: RAG ama takvim filtresi/Ã¶nceliÄŸiyle
â€¢	belge_form/prosedur: RAG (gerekirse multi-retrieval)
4) DokÃ¼man dÄ±ÅŸÄ± bilgi Ã¼retmeyi engelle
â€¢	Cevap formatÄ±: â€œKaynak + alÄ±ntÄ±/parÃ§a + cevapâ€
â€¢	Confidence check: Top-k retrieval skorlarÄ± Ã§ok dÃ¼ÅŸÃ¼kse veya iÃ§erik soruyla alakasÄ±zsa:
o	â€œBu bilgi saÄŸlanan dokÃ¼manlarda bulunamadÄ±.â€ deyip
o	kullanÄ±cÄ±ya â€œhangi belgeyle ilgili?â€ gibi yÃ¶nlendirme yap.
â€¢	SÄ±kÄ± sistem prompt: â€œSadece verilen metinlere dayan, aksi halde â€˜bulamadÄ±mâ€™ de.â€
UIâ€™da kaynakar bÃ¶lÃ¼mÃ¼ eklenebilir
5) Retrieval ayarlarÄ± (LangChain tarafÄ±)
Ä°lk sÃ¼rÃ¼m iÃ§in pratik ayarlar:
â€¢	similarity_search(k=4-6)
â€¢	sonra MMR (max marginal relevance) dene (tekrar eden chunkâ€™larÄ± azaltÄ±r)
â€¢	â€œtakvimâ€ sorularÄ±nda k=8 iyi olabiliyor (Ã§ok tarih var)
AyrÄ±ca iki aÅŸamalÄ± retrieval Ã§ok iyi sonuÃ§ verir:
1.	hÄ±zlÄ± retrieval (k=12)
2.	rerank / filtreleme (en alakalÄ± 4-6â€™yÄ± LLMâ€™e ver)
6) Test seti hazÄ±rla
20â€“40 soru yaz ve etiketle:
â€¢	10 adet SSS
â€¢	10 adet EK/form doldurma
â€¢	10 adet takvim/son tarih
â€¢	5 adet â€œdokÃ¼manda yokâ€ (out-of-scope)
â€¢	5 adet teknik/selamlama
Her soru iÃ§in beklenen:
â€¢	doÄŸru intent
â€¢	doÄŸru kaynak dokÃ¼man
â€¢	doÄŸru cevap / â€œbulamadÄ±mâ€ davranÄ±ÅŸÄ±
7) Frontend entegrasyonu (Next.js)
â€¢	sohbet ekranÄ±
â€¢	â€œKaynaklarâ€ dropdown (cevabÄ±n dayandÄ±ÄŸÄ± dokÃ¼man parÃ§alarÄ±)
â€¢	geri bildirim: ğŸ‘ğŸ‘ (â€œyanÄ±t doÄŸru mu?â€)
â€¢	â€œBu cevap hangi dokÃ¼mandan geldi?â€ link/etiket
Åu an gerekli 3 somut Ã§Ä±ktÄ±
1.	Ingestion scripti (dokÃ¼manlarÄ± okuyup Chromaâ€™yÄ± oluÅŸturan)
2.	Router (intent + rule-based + RAG) akÄ±ÅŸÄ±
3.	Evaluation/test dosyasÄ± (20â€“40 soru)

EK Ã–NERÄ°LER:
1. Ingestion AÅŸamasÄ±: TablolarÄ± "satÄ±r bazlÄ± metin" yaparken, arka planda Markdown tablosu (| Tarih | Ä°ÅŸlem |) formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmeyi dene. Modern LLM'ler Markdown yapÄ±larÄ±nÄ± Ã§ok iyi anlar ve tarih-iÅŸlem eÅŸleÅŸmelerindeki kayÄ±plarÄ± sÄ±fÄ±ra indirir.
2. Intent Detection AracÄ± (Router AÅŸamasÄ±) Intent detection iÅŸlemi iÃ§in LLM Ã§aÄŸrÄ±sÄ± yapmak sistemi yavaÅŸlatabilir. Bunun yerine hafif bir NLP sÄ±nÄ±flandÄ±rÄ±cÄ± (Ã¶rneÄŸin Hugging Face Zero-Shot Classification veya SetFit) ya da basit regex kurallarÄ± (Ã¶zellikle takvim ve belge sorularÄ± iÃ§in) kullanarak yÃ¶nlendirmeyi Ã§ok daha hÄ±zlÄ± yapabilirsin.
3. Reranker SeÃ§imi (Retrieval AÅŸamasÄ±) Ä°ki aÅŸamalÄ± retrieval yaparken ikinci aÅŸama (reranking) iÃ§in aÃ§Ä±k kaynaklÄ± ve hafif bir model olan bge-reranker (Hugging Face) kullanÄ±labilir. "K=12 getir, en iyi 5'i LLM'e ver" mantÄ±ÄŸÄ±nÄ± kusursuz Ã§alÄ±ÅŸtÄ±rÄ±r.
4. Test Seti Metrikleri (Evaluation AÅŸamasÄ±) Test setini manuel deÄŸerlendirmek yerine, RAGAS veya TruLens gibi RAG Ã¶zelinde evaluation yapan kÃ¼tÃ¼phanelere gÃ¶z atÄ±labilir. "Answer Relevance" (Cevap soruyla ne kadar alakalÄ±?) ve "Context Precision" (Gelen dokÃ¼man ne kadar doÄŸru?) gibi istatistiksel metrikler sunulabilir.


EÄŸitim DosyalarÄ±:
1- Ä°ÅŸ yeri eÄŸitimi yÃ¶nergesi. âœ”âœ”âœ”YÃœKLENDÄ°

2- EK dosyalarÄ±nÄ±n hepsi. âœ”âœ”âœ”YÃœKLENDÄ°

3- 2025-2026 iÅŸ yeri eÄŸitimi akÄ±ÅŸ ÅŸemasÄ± âœ”âœ”âœ”YÃœKLENDÄ°

4- Marmara sayfasÄ±ndaki soru cevaplar  âœ”âœ”âœ” YÃœKLENDÄ°

5- Classroom toplantÄ± notlarÄ± âœ”âœ”âœ” YÃœKLENDÄ°

6- CLASSROOM DUYURULARI âœ”âœ”âœ” YÃœKLENDÄ°


